{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45554325-8f75-48c8-8ba9-aed45dcb08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb9192-e466-478b-a0c3-73d143cdf96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import timedelta, datetime\n",
    "local_tz = pytz.timezone('America/Toronto') # Set local timezone for InfluxDB based times calculations\n",
    "today=datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f637e75-686a-4113-8ecf-7fa9481639c3",
   "metadata": {},
   "source": [
    "#### Note: if you did not create new data for the model training, a sample is provided in this repository. \n",
    "#### To use it, ensure that in the next cell the instruction with the file name lt_results_2022-10-01.csv in it is executed and not the one using \"today's\" date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bf5a5-3e93-4c8c-b109-3efc57a08be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('lt_results_'+today+'.csv', index_col='DateTime', parse_dates=True)\n",
    "data = pd.read_csv('lt_results_2022-10-01.csv', index_col='DateTime', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80374cad-a6a8-4db0-8039-8b2670da9ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957d66c-fae7-49f5-9674-66e59d2f5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['req2xx', 'testDurationSeconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c7600-1b6d-4a9c-ad7a-8f661f6e108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data.mean_tps,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0) # we are setting the seed here\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d93507-0f5c-44dc-a45c-bc7aea1bdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'mean_tps'\n",
    "X_train = X_train.drop(target_var, axis=1)\n",
    "X_test = X_test.drop(target_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf4ad7-321a-408d-9b2e-85b0d8e9c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeed1b5-6c07-468f-8285-28afa8a9f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScaler = StandardScaler()\n",
    "targetStdScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5834d0d-d4ef-4489-b336-ad2e2eb16bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = stdScaler.fit_transform(X_train.values)\n",
    "y_train_scaled = targetStdScaler.fit_transform(y_train.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcf64f-7cba-48cf-ae4b-c7adfcd20895",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = stdScaler.transform(X_test.values)\n",
    "y_test_scaled = targetStdScaler.transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93a29e-c6ed-4bb3-85f1-87377ecc8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc92ec-201d-4f4c-83c6-9a4c6da04302",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = torch.FloatTensor(X_train_scaled)\n",
    "y_train_scaled = torch.FloatTensor(y_train_scaled)\n",
    "X_test_scaled = torch.FloatTensor(X_test_scaled)\n",
    "y_test_scaled = torch.FloatTensor(y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ef366-59de-4e16-ad6c-1dbc7004d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPMLasp(nn.Module):\n",
    "    def __init__(self, input, layerSize, hidden, output):\n",
    "        super(MLPMLasp, self).__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        #input layer\n",
    "        self.net.append(nn.Linear(input,layerSize))\n",
    "        self.net.append(nn.ReLU())\n",
    "        \n",
    "        #hidden layers in a loop\n",
    "        for i in range(hidden):\n",
    "            self.net.append(nn.Linear(layerSize,layerSize))\n",
    "            self.net.append(nn.ReLU())\n",
    "\n",
    "        #output\n",
    "        self.net.append(nn.Linear(layerSize,output))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f0b6f-2da1-47e9-b671-679e21cf7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb45a5-fd25-413f-a87c-61d851d247f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = X_train_scaled.shape[1]\n",
    "colList = ['HiddenLayers', 'R2Score', 'MAE', 'MSE', 'MAPE', 'model', 'TrainLoses', 'TestLoses', 'TrainPredictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517af96-bf8a-46f2-9172-21f490970a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is the reference for creating and training the models inside the Jupyter notebook pod. We will evaluate it against the Ray cluster distributed one\n",
    "def createModel(testResultsFrame, inputSize, layerSize, loops, \n",
    "                y_train, X_train, y_test, X_test, \n",
    "                targetScaler, labelSet):\n",
    "    \n",
    "    print(f'Creating models using layer size = {layerSize} on set = {labelSet}.\\n')\n",
    "    for i in range(loops):\n",
    "        print(f'Create and training model with {i} hidden layers\\n')\n",
    "        model = MLPMLasp(inputSize, layerSize, i, 1)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        train_loses = np.zeros(epochs)\n",
    "        test_loses = np.zeros(epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            #forward and get a prediction\n",
    "            y_pred_train = model.forward(X_train)\n",
    "            #calculate the loss\n",
    "            loss = criterion(y_pred_train, y_train)\n",
    "            train_loses[epoch] = loss\n",
    "\n",
    "            #perform backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #save the test loss to compare train vs test scores\n",
    "            y_eval = model.forward(X_test)\n",
    "            test_loss = criterion(y_eval, y_test)\n",
    "            test_loses[epoch] = test_loss\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            y_pred_scaled = model.forward(X_test)\n",
    "            \n",
    "        #Evaluate metrics\n",
    "        y_pred = targetScaler.inverse_transform(y_pred_scaled)\n",
    "        r2_score = metrics.r2_score(y_test, y_pred_scaled)\n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred_scaled)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred_scaled)\n",
    "        mape = metrics.mean_absolute_percentage_error(y_test, y_pred_scaled)\n",
    "        row = [i, r2_score, mae, mse, mape, model, train_loses, test_loses, y_pred]\n",
    "        df = pd.DataFrame(np.array(row, dtype=object).reshape(1, len(colList)), columns=colList)\n",
    "        testResultsFrame = pd.concat([testResultsFrame, df], ignore_index=True)\n",
    "\n",
    "        del(model)\n",
    "        \n",
    "    return testResultsFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f8272-0ba4-42ba-94e3-1bca953213c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "testResDataFrame = pd.DataFrame(columns=colList)\n",
    "layerSize = 64\n",
    "loops = 15\n",
    "testResDataFrame = createModel(testResDataFrame, inputSize, layerSize, loops, \n",
    "                               y_train_scaled, X_train_scaled,\n",
    "                               y_test_scaled, X_test_scaled, \n",
    "                               targetStdScaler, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e5d0a-7902-4955-a2f3-a0db0f485580",
   "metadata": {},
   "outputs": [],
   "source": [
    "testResDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b51ff-13ed-4041-a65f-66c92369164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot train vs validation\n",
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(testResDataFrame['R2Score'])\n",
    "plt.plot(testResDataFrame['MAE'])\n",
    "#plt.plot(testResDataFrame['MSE'])\n",
    "plt.title('Training Scores MLP')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['MAE'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b5e66-cbae-416b-830b-9147b00521c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the IDX value where the MAE is smallest\n",
    "minMaeIDX = testResDataFrame.loc[testResDataFrame['MAE']==testResDataFrame['MAE'].min()].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84cf95-e1e2-494e-9791-e39c0f956b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testResDataFrame.iloc[minMaeIDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac8967-4a55-4eab-b2b8-1a4824eb9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MLP_std = testResDataFrame['TrainPredictions'][minMaeIDX]\n",
    "# Plot prediction vs original\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(range(y_test.shape[0]),y_test,label=\"Original Data\", alpha=0.6, c='red')\n",
    "plt.scatter(range(y_pred_MLP_std.shape[0]),y_pred_MLP_std,label=\"Predicted Data\", \n",
    "            alpha=0.6, c='black')\n",
    "plt.ylabel('Mean TPS')\n",
    "plt.xlabel('Test Records')\n",
    "plt.title('MLP Std Model for X_test dataset prediction vs original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0e944-5206-4804-aa48-3e3daea4573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loses = testResDataFrame['TrainLoses'][minMaeIDX]\n",
    "test_loses = testResDataFrame['TestLoses'][minMaeIDX]\n",
    "#Plot train vs validation\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_loses)\n",
    "plt.plot(test_loses)\n",
    "plt.title('Test vs Train loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb4d54-aa38-4b06-b276-c0a8b0a1da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_URI='http://mlflow-server.mlflow-strangiato.svc.cluster.local:8080/'\n",
    "#MLFLOW_URI='http://localhost:8080/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0c47d-54ac-4bf3-96ad-f2faaa3f6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RAY_IGNORE_UNHANDLED_ERRORS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df4ff5-c566-494c-96f0-921e330a9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import ray\n",
    "from codeflare_sdk import TokenAuthentication, Cluster, ClusterConfiguration\n",
    "from codeflare_sdk import generate_cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc1e95-1ea5-4396-b63f-03f917042e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = TokenAuthentication(\n",
    "    token = \"sha256~zAPMzZL-O4dWaBL8oMKXk2Wq8UtUiSb4JwrWEiFe3Cs\", # execute ocp whoami -t on the authenticated cluster to obtain the token\n",
    "    server = \"https://api.cluster-ffqgg.ffqgg.sandbox1386.opentlc.com:6443\",\n",
    "    skip_tls = False\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6536430-c76d-4e81-ba82-25de943b3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create required TLS cert and export the environment variables to enable TLS\n",
    "generate_cert.generate_tls_cert('raycluster-complete', 'raycluster')\n",
    "generate_cert.export_env('raycluster-complete', 'raycluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716937e-355b-46e3-9b1a-24aab229a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_endpoint = 'ray://raycluster-complete-head-svc.raycluster.svc.cluster.local:10001' # ensure your ray cluster URL is correct\n",
    "ray.shutdown()\n",
    "ray.init(address=ray_endpoint, logging_level=logging.ERROR, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd0083-3b45-4ba9-be73-59486f27b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76ab4b-f926-45ad-921f-0042bc1c5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccb0e3-083c-458e-a141-f95e4309a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.integrations.mlflow import setup_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e895b-de5d-440b-98dd-5384735e9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def createRemoteModel(inputSize, layerSize, hiddenSize, \n",
    "                y_train, X_train, y_test, X_test, \n",
    "                targetScaler, labelSet):\n",
    "\n",
    "    mlflow_exp_name = f'mlasp-1-{labelSet}-{hiddenSize}'\n",
    "    mlflow_ray_config = None\n",
    "    mlflow_ray = setup_mlflow(config=mlflow_ray_config,\n",
    "                              tracking_uri=MLFLOW_URI,\n",
    "                              registry_uri=MLFLOW_URI,\n",
    "                              create_experiment_if_not_exists=True,\n",
    "                              rank_zero_only=False,\n",
    "                             experiment_name=mlflow_exp_name)\n",
    "    \n",
    "    print(f'Create and training model with {hiddenSize} hidden layers using layer size = {layerSize} on set = {labelSet}.\\n')\n",
    "    model = MLPMLasp(inputSize, layerSize, hiddenSize, 1)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loses = np.zeros(epochs)\n",
    "    test_loses = np.zeros(epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #forward and get a prediction\n",
    "        y_pred_train = model.forward(X_train)\n",
    "        #calculate the loss\n",
    "        loss = criterion(y_pred_train, y_train)\n",
    "        train_loses[epoch] = loss\n",
    "\n",
    "        #perform backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #save the test loss if you want to compare train vs test scores\n",
    "        y_eval = model.forward(X_test)\n",
    "        test_loss = criterion(y_eval, y_test)\n",
    "        test_loses[epoch] = test_loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model.forward(X_test)\n",
    "    \n",
    "    #Evaluate metrics\n",
    "    y_pred = targetScaler.inverse_transform(y_pred_scaled)\n",
    "    y_test_orig = targetScaler.inverse_transform(y_test)\n",
    "    r2_score = metrics.r2_score(y_test, y_pred_scaled)\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred_scaled)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred_scaled)\n",
    "    mape = metrics.mean_absolute_percentage_error(y_test, y_pred_scaled)\n",
    "    \n",
    "    row = [i, r2_score, mae, mse, mape, model, train_loses, test_loses, y_pred]\n",
    "    \n",
    "    fig=plt.figure(figsize=(20,10))\n",
    "    plt.scatter(range(y_test_orig.shape[0]),y_test_orig,label=\"Original Data\", alpha=0.6, c='red')\n",
    "    plt.scatter(range(y_pred.shape[0]),y_pred,label=\"Predicted Data\", \n",
    "                alpha=0.6, c='black')\n",
    "    plt.ylabel('Mean TPS')\n",
    "    plt.xlabel('Test Records')\n",
    "    plt.title('MLP StdScaler Model for X_test dataset prediction vs original')\n",
    "    plt.legend()    \n",
    "\n",
    "    mlflow_ray.log_figure(fig,f\"{mlflow_exp_name}.png\")\n",
    "    \n",
    "    mlflow_ray.log_param(\"batch_size\", 32)\n",
    "    mlflow_ray.log_param(\"layer_size\", layerSize)\n",
    "    mlflow_ray.log_param(\"hidden_layers\", loops)\n",
    "    mlflow_ray.log_param(\"activation_function\", \"relu\")\n",
    "    mlflow_ray.log_param(\"dense_kernel_initializer\", \"torchnormal\")\n",
    "    mlflow_ray.log_param(\"epochs\", epochs)\n",
    "    mlflow_ray.log_param(\"learning_rate\", 0.001)\n",
    "    mlflow_ray.log_param(\"optimizer\", \"adam\")\n",
    "\n",
    "    mlflow_ray.log_metric(\"mae\", mae)\n",
    "    mlflow_ray.log_metric(\"mse\", mse)\n",
    "    mlflow_ray.log_metric(\"mape\", mape)\n",
    "    mlflow_ray.log_metric(\"r2_score\", r2_score)\n",
    "\n",
    "    model_onnx = torch.onnx.dynamo_export(model, X_train[0])\n",
    "    mlflow_ray.onnx.log_model(model_onnx.model_proto, f\"model-{mlflow_exp_name}\")\n",
    "\n",
    "    row = [hiddenSize, r2_score, mae, mse, mape]\n",
    "    del(model)\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30b1eb-e528-4baa-9304-ad7ddcc5447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "testResDataFrame2 = []\n",
    "layerSize = 64\n",
    "loops = 15\n",
    "\n",
    "for i in range(loops):\n",
    "    rowResult = createRemoteModel.remote(inputSize, layerSize, i, \n",
    "                        y_train_scaled, X_train_scaled,\n",
    "                        y_test_scaled, X_test_scaled, \n",
    "                        targetStdScaler, labelSet='all_ray')\n",
    "    testResDataFrame2.append(rowResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fbf5c-b1a7-4c83-989d-239460e10d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testResDataFrame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e103dbd-4a6d-41d8-b5b2-5638606a3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tResDF2 = ray.get(testResDataFrame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6ca12-c6c4-4d46-ae81-f3653516fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b806634-531a-4f67-9064-ab6d113a2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "colList2=colList.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef01906-34c7-4d31-9161-4397cdf9049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tResDF2, columns=colList2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b76c0d-7588-4492-a42e-3a378b693509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f8ec4-f1f9-4e97-bd5b-7a12645709eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaeIDX_ray = df.loc[df['MAE']==df['MAE'].min()].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61fc31-128e-482f-b482-385946e2d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[minMaeIDX_ray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a7615-ab1c-43ec-9c39-9551d1f5c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot train vs validation\n",
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(df['R2Score'])\n",
    "plt.plot(df['MAE'])\n",
    "#plt.plot(df['MSE'])\n",
    "plt.title('Training Scores MLP')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['MAE'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa84600-a72f-44cb-b118-bae15a88377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a312405a-05b5-4ac7-acaa-558113126424",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8c1b1-7659-4e05-bd87-a3170d1bd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = [[True, 21, 277, 1712, 262, 7, 31, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9f096-e0ad-4ad4-826d-89a168fac930",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec = stdScaler.transform(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f1a2b-e189-4aec-be47-e789bc7c328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec = torch.FloatTensor(test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd1362-c865-4d05-85a9-6af58eb5dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24226c1f-ec59-44eb-b64a-b1c4adc78c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model = testResDataFrame['model'][minMaeIDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d179b8b-0840-4f71-9aa1-75608e840f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_scaled = ml_model.forward(test_rec)\n",
    "\n",
    "y_pred = targetStdScaler.inverse_transform(y_pred_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29cd797-e15f-43ea-ad70-e6b0dde39270",
   "metadata": {},
   "source": [
    "### Save the scalers for the inference calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe882678-e78f-4b9e-9707-ab0a9e16e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(targetStdScaler,'target_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21964a3b-33c8-43fc-bcac-cd9c663d5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(stdScaler,'standard_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d5365-d4fa-44bc-93db-0935482fefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(ml_model, test_rec, 'torch_mlasp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee2ed0-0853-45a8-8d7b-15769afb404a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch-GPU",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
