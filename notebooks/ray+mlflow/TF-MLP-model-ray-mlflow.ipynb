{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7449aba8-9b91-4265-8406-b34bca561a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5698b57-2887-4b51-a8e7-8c7aa8514ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4b99c9-801d-471d-a895-0925874c85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34794a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 20:45:40.860559: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 20:45:46.153097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-18 20:45:46.153187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-18 20:45:46.153198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac816ae9-57fe-443b-a298-411395db32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import timedelta, datetime\n",
    "local_tz = pytz.timezone('America/Toronto') # Set local timezone for InfluxDB based times calculations\n",
    "today=datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7839bf0-de93-4191-bb7b-04f426be3a6b",
   "metadata": {},
   "source": [
    "#### Note: if you did not create new data for the model training, a sample is provided in this repository. \n",
    "#### To use it, ensure that in the next cell the instruction with the file name lt_results_2022-10-01.csv in it is executed and not the one using \"today's\" date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44351c78-7bd2-4ffc-8029-f971e62d6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('lt_results_'+today+'.csv', index_col='DateTime', parse_dates=True, infer_datetime_format=True)\n",
    "data = pd.read_csv('lt_results_2022-10-01.csv', index_col='DateTime', parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f3eaae-82c8-4c5b-976f-705aedf80ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asyncResp</th>\n",
       "      <th>asyncRespThreads</th>\n",
       "      <th>cThreads</th>\n",
       "      <th>jacptQSize</th>\n",
       "      <th>jacptThreads</th>\n",
       "      <th>ltTargetSize</th>\n",
       "      <th>mean_tps</th>\n",
       "      <th>numConnections</th>\n",
       "      <th>req2xx</th>\n",
       "      <th>testDurationSeconds</th>\n",
       "      <th>timeoutSeconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-28 15:25:25+00:00</th>\n",
       "      <td>True</td>\n",
       "      <td>21.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>307.015227</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50679.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 15:34:42+00:00</th>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2788.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347.427221</td>\n",
       "      <td>35.0</td>\n",
       "      <td>146793.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 15:47:10+00:00</th>\n",
       "      <td>True</td>\n",
       "      <td>28.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>138.693699</td>\n",
       "      <td>14.0</td>\n",
       "      <td>84757.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 15:56:35+00:00</th>\n",
       "      <td>True</td>\n",
       "      <td>14.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>158.212165</td>\n",
       "      <td>16.0</td>\n",
       "      <td>68515.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 16:01:09+00:00</th>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>245.806605</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34173.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           asyncResp  asyncRespThreads  cThreads  jacptQSize  \\\n",
       "DateTime                                                                       \n",
       "2022-09-28 15:25:25+00:00       True              21.0     277.0      1712.0   \n",
       "2022-09-28 15:34:42+00:00       True              30.0     173.0      2788.0   \n",
       "2022-09-28 15:47:10+00:00       True              28.0     125.0      1411.0   \n",
       "2022-09-28 15:56:35+00:00       True              14.0     115.0      1176.0   \n",
       "2022-09-28 16:01:09+00:00       True              30.0     226.0      2296.0   \n",
       "\n",
       "                           jacptThreads  ltTargetSize    mean_tps  \\\n",
       "DateTime                                                            \n",
       "2022-09-28 15:25:25+00:00         262.0           7.0  307.015227   \n",
       "2022-09-28 15:34:42+00:00         158.0           1.0  347.427221   \n",
       "2022-09-28 15:47:10+00:00         110.0          15.0  138.693699   \n",
       "2022-09-28 15:56:35+00:00         100.0          12.0  158.212165   \n",
       "2022-09-28 16:01:09+00:00         211.0          12.0  245.806605   \n",
       "\n",
       "                           numConnections    req2xx  testDurationSeconds  \\\n",
       "DateTime                                                                   \n",
       "2022-09-28 15:25:25+00:00            31.0   50679.0                165.0   \n",
       "2022-09-28 15:34:42+00:00            35.0  146793.0                423.0   \n",
       "2022-09-28 15:47:10+00:00            14.0   84757.0                611.0   \n",
       "2022-09-28 15:56:35+00:00            16.0   68515.0                433.0   \n",
       "2022-09-28 16:01:09+00:00            25.0   34173.0                139.0   \n",
       "\n",
       "                           timeoutSeconds  \n",
       "DateTime                                   \n",
       "2022-09-28 15:25:25+00:00             5.0  \n",
       "2022-09-28 15:34:42+00:00             5.0  \n",
       "2022-09-28 15:47:10+00:00             5.0  \n",
       "2022-09-28 15:56:35+00:00             5.0  \n",
       "2022-09-28 16:01:09+00:00             5.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2435b5e3-39c5-4066-b449-1854f7479d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['req2xx', 'testDurationSeconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451236eb-36ce-4da6-b805-7d43345c50a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74, 9), (9, 9))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data.mean_tps,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0) # we are setting the seed here\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db82e83-775c-4ed9-bb92-33eb69eba066",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'mean_tps'\n",
    "X_train = X_train.drop(target_var, axis=1)\n",
    "X_test = X_test.drop(target_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af28291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d8f4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScaler = StandardScaler()\n",
    "targetStdScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7763e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = stdScaler.fit_transform(X_train.values)\n",
    "y_train_scaled = targetStdScaler.fit_transform(y_train.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1441a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = stdScaler.transform(X_test.values)\n",
    "y_test_scaled = targetStdScaler.transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf5f2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Nets imports\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7b5b4b-5c0a-46c1-8fbe-a4e6c627d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fa7afdc-69cc-4197-ac03-fd1f03535653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve AWS access from the data connection attached to the workbench\n",
    "aws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "aws_secret_access_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "endpoint_url = os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "bucket_name = os.environ[\"AWS_S3_BUCKET\"]\n",
    "region_name = os.environ[\"AWS_DEFAULT_REGION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ca337d-6594-43a8-841b-996fb9328d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "verboseLevel=0\n",
    "validationSplit=0.2\n",
    "batchSize=30\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cd199ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback preparation\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.5,\n",
    "                              patience=2,\n",
    "                              verbose=verboseLevel,\n",
    "                              mode='min',\n",
    "                              min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d827c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = X_train_scaled.shape[1]\n",
    "colList = ['HiddenLayers', 'R2Score', 'MAE', 'MSE', 'MAPE', 'H5FileName', 'TrainHistory', 'TrainPredictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efb72f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loss = 'mae'\n",
    "#loss = 'mse'\n",
    "measure_metrics = ['mae', 'mse']\n",
    "#measure_metrics = ['mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d15c8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is the reference for creating and training the models inside the Jupyter notebook pod. We will evaluate it against the Ray cluster distributed one\n",
    "def createModel(testResultsFrame, layerSize, loops, target_loss, measure_metrics,\n",
    "                y_train, X_train, y_test, X_test, targetScaler, labelSet):\n",
    "    print(f'Creating model using layer size = {layerSize} on set = {labelSet}.\\n')\n",
    "    for i in range(loops):\n",
    "        print(f'Training on {i} hidden layers\\n')\n",
    "        model = Sequential()\n",
    "        model.add(Dense(layerSize, kernel_initializer='normal',\n",
    "                        input_dim=inputSize, activation='relu'))\n",
    "        for j in range(i):\n",
    "            model.add(Dense(layerSize, \n",
    "                            kernel_initializer='normal', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(1, kernel_initializer='normal', \n",
    "                        activation='linear'))\n",
    "\n",
    "        optmzr=Adam(learning_rate=0.001)    \n",
    "        model.compile(optimizer=optmzr, loss=target_loss, metrics=measure_metrics)\n",
    "\n",
    "        model_h5_name = 'mlp_' + str(layerSize)+ '_' + str(i) + '_model_std_' + labelSet + '.h5'\n",
    "        checkpoint_nn_std = ModelCheckpoint(model_h5_name,\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=verboseLevel,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='min')\n",
    "        callbacks_list_nn_std = [checkpoint_nn_std, reduce_lr]\n",
    "\n",
    "        history_MLP_std = model.fit(X_train, y_train,\n",
    "                                    batch_size=batchSize, \n",
    "                                    validation_split=validationSplit, \n",
    "                                    epochs=epochs, verbose=verboseLevel,\n",
    "                                    callbacks=callbacks_list_nn_std)\n",
    "\n",
    "        #reload the best model!\n",
    "        model_new = load_model(model_h5_name)\n",
    "        #Predict\n",
    "        y_pred_scaled = model_new.predict(X_test)\n",
    "        #Evaluate metrics\n",
    "        y_pred = targetScaler.inverse_transform(y_pred_scaled)\n",
    "        r2_score = metrics.r2_score(y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "        #store values\n",
    "        row = [i, r2_score, mae, mse, mape, model_h5_name, history_MLP_std, y_pred]\n",
    "        df = pd.DataFrame(np.array(row, dtype=object).reshape(1, len(colList)), columns=colList)\n",
    "        testResultsFrame = testResultsFrame.append(df, ignore_index=True)\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        del(model)\n",
    "        del(model_new)\n",
    "        \n",
    "    return testResultsFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f914d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model using layer size = 64 on set = all.\n",
      "\n",
      "Training on 0 hidden layers\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 20:45:49.049597: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-18 20:45:49.049627: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-18 20:45:49.049660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (etsad-workbench-0): /proc/driver/nvidia/version does not exist\n",
      "2023-09-18 20:45:49.049890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "Training on 1 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Training on 2 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Training on 3 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Training on 4 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Training on 5 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Training on 6 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Training on 7 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Training on 8 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Training on 9 hidden layers\n",
      "\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Training on 10 hidden layers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testResDataFrame = pd.DataFrame(columns=colList)\n",
    "layerSize = 64\n",
    "loops = 15\n",
    "testResDataFrame = createModel(testResDataFrame, layerSize, loops, \n",
    "                        target_loss, measure_metrics,\n",
    "                        y_train_scaled, X_train_scaled,\n",
    "                        y_test, X_test_scaled, \n",
    "                        targetStdScaler, 'all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56145d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot train vs validation\n",
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(testResDataFrame['R2Score'])\n",
    "plt.plot(testResDataFrame['MAE'])\n",
    "#plt.plot(testResDataFrame['MSE'])\n",
    "plt.title('Training Scores MLP')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['MAE'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707005cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the IDX value where the MAE is smallest\n",
    "minMaeIDX = testResDataFrame.loc[testResDataFrame['MAE']==testResDataFrame['MAE'].min()].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "testResDataFrame.iloc[minMaeIDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MLP_std = testResDataFrame['TrainPredictions'][minMaeIDX]\n",
    "# Plot prediction vs original\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(range(y_test.shape[0]),y_test,label=\"Original Data\", alpha=0.6, c='red')\n",
    "plt.scatter(range(y_pred_MLP_std.shape[0]),y_pred_MLP_std,label=\"Predicted Data\", \n",
    "            alpha=0.6, c='black')\n",
    "plt.ylabel('Mean TPS')\n",
    "plt.xlabel('Test Records')\n",
    "plt.title('MLP Std Model for X_test dataset prediction vs original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef764d-a830-4793-aca4-b860a9cbf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_URI='http://mlflow-server.mlflow-strangiato.svc.cluster.local:8080/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77202e7-ccd2-4ad7-86c0-bca5e87f99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"RAY_IGNORE_UNHANDLED_ERRORS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a21de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65445577-1974-4e01-988c-90fdfe3bc93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_endpoint = 'ray://raycluster-complete-head-svc.raycluster.svc.cluster.local:10001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7111cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.init(address=ray_endpoint, logging_level=logging.ERROR, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb4e80-3604-410b-bf9f-ab369ddc4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8887f-6c0b-45e4-a6c7-a00ffce405cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217b546-0eb2-44e7-88f2-15d2774aca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.integrations.mlflow import setup_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def createRemoteModel(layerSize, loops, target_loss, measure_metrics,\n",
    "                y_train, X_train, y_test, X_test, targetScaler, labelSet):\n",
    "        \n",
    "    mlflow_exp_name = f'mlasp-1-{labelSet}-{loops}'\n",
    "    mlflow_ray_config = None\n",
    "    mlflow_ray = setup_mlflow(config=mlflow_ray_config,\n",
    "                              tracking_uri=MLFLOW_URI,\n",
    "                              registry_uri=MLFLOW_URI,\n",
    "                              create_experiment_if_not_exists=True,\n",
    "                              rank_zero_only=False,\n",
    "                             experiment_name=mlflow_exp_name)\n",
    "    \n",
    "    print(f'Creating model using {loops} hidden layers of size = {layerSize} on set = {labelSet}.\\n')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layerSize, kernel_initializer='normal',\n",
    "                    input_dim=inputSize, activation='relu'))\n",
    "    for j in range(loops):\n",
    "        model.add(Dense(layerSize, \n",
    "                        kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer='normal', \n",
    "                    activation='linear'))\n",
    "\n",
    "    optmzr=Adam(learning_rate=0.001)    \n",
    "    model.compile(optimizer=optmzr, loss=target_loss, metrics=measure_metrics)\n",
    "\n",
    "    model_h5_name = 'mlp_' + str(layerSize)+ '_' + str(loops) + '_model_std_' + labelSet + '.h5'\n",
    "    checkpoint_nn_std = ModelCheckpoint(model_h5_name,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=verboseLevel,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "    callbacks_list_nn_std = [checkpoint_nn_std, reduce_lr]\n",
    "\n",
    "    history_MLP_std = model.fit(X_train, y_train,\n",
    "                                batch_size=batchSize, \n",
    "                                validation_split=validationSplit, \n",
    "                                epochs=epochs, verbose=verboseLevel,\n",
    "                                callbacks=callbacks_list_nn_std)\n",
    "\n",
    "    #reload the best model!\n",
    "    model_new = load_model(model_h5_name)\n",
    "    #Predict\n",
    "    y_pred_scaled = model_new.predict(X_test)\n",
    "    #Evaluate metrics\n",
    "    y_pred = targetScaler.inverse_transform(y_pred_scaled)\n",
    "    r2_score = metrics.r2_score(y_test, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    fig=plt.figure(figsize=(20,10))\n",
    "    plt.scatter(range(y_test.shape[0]),y_test,label=\"Original Data\", alpha=0.6, c='red')\n",
    "    plt.scatter(range(y_pred.shape[0]),y_pred,label=\"Predicted Data\", \n",
    "                alpha=0.6, c='black')\n",
    "    plt.ylabel('Mean TPS')\n",
    "    plt.xlabel('Test Records')\n",
    "    plt.title('MLP StdScaler Model for X_test dataset prediction vs original')\n",
    "    plt.legend()    \n",
    "\n",
    "    mlflow_ray.log_figure(fig,f\"{mlflow_exp_name}.png\")\n",
    "    \n",
    "    mlflow_ray.log_param(\"batch_size\", batchSize)\n",
    "    mlflow_ray.log_param(\"layer_size\", layerSize)\n",
    "    mlflow_ray.log_param(\"hidden_layers\", loops)\n",
    "    mlflow_ray.log_param(\"activation_function\", \"relu\")\n",
    "    mlflow_ray.log_param(\"dense_kernel_initializer\", \"normal\")\n",
    "    mlflow_ray.log_param(\"epochs\", epochs)\n",
    "    mlflow_ray.log_param(\"learning_rate\", 0.001)\n",
    "    mlflow_ray.log_param(\"optimizer\", \"adam\")\n",
    "\n",
    "    mlflow_ray.log_metric(\"mae\", mae)\n",
    "    mlflow_ray.log_metric(\"mse\", mse)\n",
    "    mlflow_ray.log_metric(\"mape\", mape)\n",
    "    mlflow_ray.log_metric(\"r2_score\", r2_score)\n",
    "    \n",
    "    model_onnx,_ = tf2onnx.convert.from_keras(model_new)\n",
    "    mlflow_ray.onnx.log_model(model_onnx, f\"model-{mlflow_exp_name}\")\n",
    "\n",
    "    row = [loops, r2_score, mae, mse, mape]\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "testResDataFrame2 = []\n",
    "layerSize = 64\n",
    "loops = 15\n",
    "\n",
    "\n",
    "for i in range(loops):\n",
    "    rowResult = createRemoteModel.remote(layerSize, i, \n",
    "                        target_loss, measure_metrics,\n",
    "                        y_train_scaled, X_train_scaled,\n",
    "                        y_test, X_test_scaled, \n",
    "                        targetStdScaler, labelSet='all_ray')\n",
    "    testResDataFrame2.append(rowResult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9db43-5d70-4421-b06c-3be7c0e5d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "testResDataFrame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47a97e-eda0-482c-b0d3-7a4b4c3991c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tResDF2 = ray.get(testResDataFrame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbf6be-17af-4037-88da-87068b278cf4",
   "metadata": {},
   "source": [
    "As you can see the ray.get() is a blocking function so it waits until all the tasks for the current job on the ray cluster have completed (in our case the 15 models training).\n",
    "This method then retrieves the results from the tasks and provides the final result (adds some extra time to compile the result0. \n",
    "As you can see the ray training and result retrieval take about 1 minute and 8 seconds vs 8 minutes and 1s the training within the notebook image). These values apply to the type of physical resources available in this cluster (your cluster results may differ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348862fa-65a6-4dd2-810c-9d3f6256a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "colList2=colList.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f183e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tResDF2, columns=colList2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9748269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaeIDX_ray = df.loc[df['MAE']==df['MAE'].min()].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078966bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[minMaeIDX_ray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07e0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot train vs validation\n",
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(df['R2Score'])\n",
    "plt.plot(df['MAE'])\n",
    "#plt.plot(df['MSE'])\n",
    "plt.title('Training Scores MLP')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['MAE'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e7a27-4151-4b8e-bcba-f288f632d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b24e8-a8e9-4a95-b7e8-46ba09ad38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = [[True, 21, 277, 1712, 262, 7, 31, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1546087",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec = stdScaler.transform(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf21aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = load_model(testResDataFrame['H5FileName'][minMaeIDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e6273-16be-4a4e-ba84-da3454406c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_model.predict(test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff876c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccfdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetStdScaler.inverse_transform(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285a26a-d409-4565-a0c4-f78088b1bede",
   "metadata": {},
   "source": [
    "### Save the scalers for the inference calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50071874",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(targetStdScaler,'target_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8986b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(stdScaler,'standard_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194a30d-e138-4560-b138-be1350e48f72",
   "metadata": {},
   "source": [
    "### Export to ONNX to run on the RHODS model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02097f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onnx, _ = tf2onnx.convert.from_keras(test_model, output_path='tf_mlasp.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8893b44-8218-4c4a-83ee-7953c889344b",
   "metadata": {},
   "source": [
    "### Upload model to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacaca1-4b2e-4ed9-a4d1-156cb31477a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a16a30-4dc3-44e6-97b3-b5223e1a1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#S3 ODF GW client\n",
    "s3_odf = boto3.client(service_name = 's3',\n",
    "                      aws_access_key_id = aws_access_key_id,\n",
    "                      aws_secret_access_key = aws_secret_access_key,\n",
    "                      region_name = 'default',\n",
    "                      endpoint_url = endpoint_url,\n",
    "                      config = botocore.client.Config(signature_version = 's3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f506d-4b61-4fbd-96b7-1ddc766aefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_odf.upload_file('tf_mlasp.onnx', bucket_name, 'models/tf_mlasp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b3213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88393ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_odf.upload_file('lt_results_2022-10-01.csv', bucket_name, 'data/lt_results_2022-10-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b4ff2-5eac-40f6-acc2-135b42ab52b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
